{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMD7ivMof0Ky",
        "outputId": "dcb61e8a-2ac6-4d05-f39a-e55c4bf6b84e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.5.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.12/dist-packages (from monai) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from monai) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.1->monai) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.1->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.1->monai) (3.0.3)\n",
            "Downloading monai-1.5.1-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nooxjDLxih-f",
        "outputId": "64cc924c-98e4-4e93-b0aa-a731b1553778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/account].\n",
            "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [clinimcl] or it does not exist.\n",
            "Are you sure you wish to set property [core/project] to clinimcl?\n",
            "\n",
            "Do you want to continue (Y/n)?  Y\n",
            "\n",
            "Updated property [core/project].\n",
            "Sun Nov  9 22:31:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   31C    P0             50W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "[device] NVIDIA A100-SXM4-80GB | torch 2.8.0+cu126 | monai 1.5.1\n"
          ]
        }
      ],
      "source": [
        "# Authenticate Google account and set up project access\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set account secasarr@ucsc.edu\n",
        "!gcloud config set project clinimcl\n",
        "\n",
        "# Confirm GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch, monai\n",
        "print(f\"[device] {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu'} | torch {torch.__version__} | monai {monai.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gcsfs\n",
        "from torch.serialization import add_safe_globals\n",
        "from monai.data.meta_tensor import MetaTensor\n",
        "from monai.utils.enums import TraceKeys\n",
        "import numpy as np\n",
        "\n",
        "# --- dynamically add numpy internals (for torch.load) ---\n",
        "safe_globals = [MetaTensor, TraceKeys]\n",
        "try:\n",
        "    import numpy.core.multiarray as multiarray\n",
        "    safe_globals.append(multiarray._reconstruct)\n",
        "except Exception as e:\n",
        "    print(f\"[warn] could not import numpy.core.multiarray._reconstruct: {e}\")\n",
        "\n",
        "try:\n",
        "    import numpy.dtype as np_dtype\n",
        "    safe_globals.append(np_dtype)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Register safe globals with PyTorch\n",
        "add_safe_globals(safe_globals)\n",
        "print(f\"[torch] registered {len(safe_globals)} safe globals for torch.load\")\n",
        "\n",
        "# --- Connect to GCS using Colab credentials ---\n",
        "fs = gcsfs.GCSFileSystem(token='google_default')\n",
        "base_path = \"gs://clinimcl-data/OASIS3\"\n",
        "preproc_path = f\"{base_path}/preprocessed\"\n",
        "raw_path = f\"{base_path}/raw\"\n",
        "\n",
        "# Verify access\n",
        "files = fs.glob(f\"{preproc_path}/**/*.pt\")\n",
        "print(f\"[gcs] Found {len(files)} preprocessed .pt files. Showing first 5:\")\n",
        "print(\"\\n\".join(files[:5]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkwPc0Trp15P",
        "outputId": "8e0aec96-cc4b-477c-a195-5a22eb4a6ba7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch] registered 3 safe globals for torch.load\n",
            "[gcs] Found 2832 preprocessed .pt files. Showing first 5:\n",
            "clinimcl-data/OASIS3/preprocessed/OAS30001_d0129.pt\n",
            "clinimcl-data/OASIS3/preprocessed/OAS30001_d0757.pt\n",
            "clinimcl-data/OASIS3/preprocessed/OAS30001_d2430.pt\n",
            "clinimcl-data/OASIS3/preprocessed/OAS30001_d3132.pt\n",
            "clinimcl-data/OASIS3/preprocessed/OAS30001_d3746.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io, torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Load ALL .pt files from your GCS bucket\n",
        "# ------------------------------------------------------------------\n",
        "all_files = [f.split(\"/\")[-1] for f in fs.ls(preproc_path) if f.endswith(\".pt\")]\n",
        "print(f\"[dataset] Using all {len(all_files)} preprocessed files\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Dataset definition\n",
        "# ------------------------------------------------------------------\n",
        "class OASIS3Dataset(Dataset):\n",
        "    def __init__(self, fs, preproc_path, subjects, target_shape=(128,128,128)):\n",
        "        self.fs = fs\n",
        "        self.files = [f\"{preproc_path}/{s}\" for s in subjects]\n",
        "        self.target_shape = target_shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def _pad_or_crop(self, x):\n",
        "        c, d, h, w = x.shape\n",
        "        td, th, tw = self.target_shape\n",
        "        # crop center if too big\n",
        "        if d > td or h > th or w > tw:\n",
        "            d0 = (d - td)//2\n",
        "            h0 = (h - th)//2\n",
        "            w0 = (w - tw)//2\n",
        "            x = x[:, d0:d0+td, h0:h0+th, w0:w0+tw]\n",
        "        # pad if too small\n",
        "        pad_d = max(0, td - x.shape[1])\n",
        "        pad_h = max(0, th - x.shape[2])\n",
        "        pad_w = max(0, tw - x.shape[3])\n",
        "        if pad_d or pad_h or pad_w:\n",
        "            x = F.pad(x, (0,pad_w,0,pad_h,0,pad_d))\n",
        "        return x\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.files[idx]\n",
        "        with self.fs.open(path, \"rb\") as f:\n",
        "            buf = io.BytesIO(f.read())\n",
        "            tensor = torch.load(buf, map_location=\"cpu\", weights_only=False)\n",
        "        tensor = tensor.float()\n",
        "        tensor = self._pad_or_crop(tensor)\n",
        "        return tensor\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Build dataset & loader for full training set\n",
        "# ------------------------------------------------------------------\n",
        "target_shape = (128,128,128)\n",
        "dataset = OASIS3Dataset(fs, preproc_path, all_files, target_shape)\n",
        "loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "\n",
        "# Smoke test\n",
        "batch = next(iter(loader))\n",
        "print(f\"[✓] Loaded batch of shape {batch.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFHHzYWltwRK",
        "outputId": "3964eeff-aaad-490f-d434-ad0a003c90c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dataset] Using all 2832 preprocessed files\n",
            "[✓] Loaded batch of shape torch.Size([2, 1, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.networks.nets import resnet50\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, in_dim=2048, proj_dim=128, hidden=2048, use_bn=True):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(in_dim, hidden), nn.GELU()]\n",
        "        if use_bn:\n",
        "            layers.append(nn.BatchNorm1d(hidden))\n",
        "        layers += [nn.Linear(hidden, proj_dim)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, l2norm=True):\n",
        "        z = self.net(x)\n",
        "        return F.normalize(z, dim=-1) if l2norm else z\n",
        "\n",
        "class ContrastiveModel(nn.Module):\n",
        "    def __init__(self, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.encoder = resnet50(spatial_dims=3, n_input_channels=1, num_classes=0)\n",
        "        self.projector = ProjectionHead(in_dim=2048, proj_dim=proj_dim)\n",
        "\n",
        "    @torch.cuda.amp.autocast(enabled=True)\n",
        "    def forward(self, x, return_feats=False):\n",
        "        feats = self.encoder(x)              # [B, 2048]\n",
        "        z = self.projector(feats)            # [B, proj_dim], L2-normalized\n",
        "        return (z, feats) if return_feats else z\n",
        "\n",
        "model = ContrastiveModel(proj_dim=128).cuda()\n",
        "print(f\"[model] total params: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFMMY8hUuxkC",
        "outputId": "a5200a7f-1634-4063-8767-f41152ebb9ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2320125725.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=True)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/init.py:582: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[model] total params: 50.62M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 5 (FAST): Longitudinal contrastive training (streaming, subject-subset per epoch, 20–30 epochs, auto-upload) =====\n",
        "# Goals for ~5h total:\n",
        "# - IMG_SIZE=96\n",
        "# - Lighter encoder (base=16)\n",
        "# - Batch=8 (adjust if OOM)\n",
        "# - Each epoch trains on ~25% of subjects (rotating subset), ~120 steps/epoch\n",
        "# - 20–30 epochs total still cover full dataset multiple times\n",
        "\n",
        "import os, io, re, time, math, random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "import gcsfs\n",
        "\n",
        "# -----------------------------\n",
        "# Speed-tuned config\n",
        "# -----------------------------\n",
        "device        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE    = 8                 # try 8 on A100; if OOM, set 6\n",
        "EPOCHS        = 10                # set 20 (or 30 if you have time)\n",
        "IMG_SIZE      = 96                # downscale from 128 -> 96 (big speedup)\n",
        "LR            = 1e-4\n",
        "TEMP          = 0.07\n",
        "POS_PROB      = 0.5\n",
        "PRINT_EVERY   = 50\n",
        "EPOCH_SUBJECT_FRACTION = 0.25     # ~25% subjects per epoch (~120 steps not 472)\n",
        "GCS_BUCKET_PREFIX = \"gs://clinimcl-data/OASIS3/preprocessed/\"\n",
        "CHECKPOINT_BUCKET = \"gs://clinimcl-data/checkpoints/\"\n",
        "\n",
        "print(f\"[env] device={device} | epochs={EPOCHS} | batch={BATCH_SIZE} | img={IMG_SIZE}\")\n",
        "\n",
        "# Perf flags\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# ----------------------------------------\n",
        "# Resize helper (keeps C=1)\n",
        "# ----------------------------------------\n",
        "def ensure_size(x: torch.Tensor, side: int = IMG_SIZE) -> torch.Tensor:\n",
        "    if x.ndim == 3:\n",
        "        x = x.unsqueeze(0)\n",
        "    if x.shape[0] != 1:\n",
        "        x = x[:1]\n",
        "    if tuple(x.shape[1:]) == (side, side, side):\n",
        "        return x\n",
        "    x = x.unsqueeze(0)\n",
        "    x = F.interpolate(x, size=(side, side, side), mode=\"trilinear\", align_corners=False)\n",
        "    return x.squeeze(0)\n",
        "\n",
        "# ----------------------------------------\n",
        "# Index GCS\n",
        "# ----------------------------------------\n",
        "fs = gcsfs.GCSFileSystem(token=\"google_default\")\n",
        "def _to_gs(p: str) -> str: return p if p.startswith(\"gs://\") else f\"gs://{p}\"\n",
        "\n",
        "raw_paths = fs.ls(GCS_BUCKET_PREFIX)\n",
        "pt_files  = [_to_gs(p) for p in raw_paths if p.lower().endswith(\".pt\")]\n",
        "print(f\"[data] files={len(pt_files)}\")\n",
        "\n",
        "_fname_re = re.compile(r\"(OAS3\\d+|OAS\\d+)\\D*?_d(\\d+)\\.pt$\", re.IGNORECASE)\n",
        "def parse_subject_day(path: str):\n",
        "    m = _fname_re.search(os.path.basename(path))\n",
        "    return (m.group(1), int(m.group(2))) if m else (None, None)\n",
        "\n",
        "subjects_full = defaultdict(list)\n",
        "for p in pt_files:\n",
        "    s, d = parse_subject_day(p)\n",
        "    if s: subjects_full[s].append((d, p))\n",
        "for s in subjects_full: subjects_full[s].sort(key=lambda t: t[0])\n",
        "\n",
        "subjects_with_pairs_full = {s: tps for s, tps in subjects_full.items() if len(tps) >= 2}\n",
        "all_subject_ids = list(subjects_full.keys())\n",
        "pair_subject_ids = list(subjects_with_pairs_full.keys())\n",
        "print(f\"[data] subjects={len(all_subject_ids)} | with≥2 tps={len(pair_subject_ids)}\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# Safe globals for torch.load\n",
        "# ----------------------------------------\n",
        "from torch.serialization import add_safe_globals\n",
        "try:\n",
        "    from monai.data.meta_tensor import MetaTensor\n",
        "    from monai.utils.enums import TraceKeys\n",
        "    add_safe_globals([MetaTensor, TraceKeys, np.ndarray])\n",
        "except Exception:\n",
        "    add_safe_globals([np.ndarray])\n",
        "\n",
        "# ----------------------------------------\n",
        "# Streaming loader (NO local cache)\n",
        "# ----------------------------------------\n",
        "def load_pt(gs_url: str) -> torch.Tensor:\n",
        "    with fs.open(gs_url, \"rb\") as f:\n",
        "        buf = io.BytesIO(f.read())\n",
        "    vol = torch.load(buf, map_location=\"cpu\", weights_only=False)\n",
        "    vol = torch.as_tensor(vol, dtype=torch.float32)\n",
        "    vmin, vmax = float(vol.min()), float(vol.max())\n",
        "    if vmax > vmin:\n",
        "        vol = (vol - vmin) / (vmax - vmin + 1e-6)\n",
        "    return ensure_size(vol).contiguous()\n",
        "\n",
        "class PairDataset(Dataset):\n",
        "    \"\"\"Pairs from a *restricted subject subset* for the current epoch.\"\"\"\n",
        "    def __init__(self, subs_all, subs_pairs, allowed_all_ids, allowed_pair_ids, p_pos=0.5):\n",
        "        self.sa = subs_all\n",
        "        self.sp = subs_pairs\n",
        "        self.ids_all  = allowed_all_ids\n",
        "        self.ids_pair = allowed_pair_ids\n",
        "        self.p_pos = p_pos\n",
        "    def __len__(self): return max(2000, len(self.ids_all)*20)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.ids_pair and (random.random() < self.p_pos):\n",
        "            s = random.choice(self.ids_pair)\n",
        "            (d1,p1),(d2,p2) = random.sample(self.sp[s], 2)\n",
        "            return load_pt(p1), load_pt(p2), 1, p1, p2\n",
        "        s1, s2 = random.sample(self.ids_all, 2)\n",
        "        d1,p1 = random.choice(self.sa[s1])\n",
        "        d2,p2 = random.choice(self.sa[s2])\n",
        "        return load_pt(p1), load_pt(p2), 0, p1, p2\n",
        "\n",
        "def make_loader_for_epoch(epoch_idx: int):\n",
        "    \"\"\"Rotate a subject subset each epoch to cover whole dataset across epochs.\"\"\"\n",
        "    rng = random.Random(epoch_idx + 12345)\n",
        "    # choose subset of subjects\n",
        "    n_all = len(all_subject_ids)\n",
        "    n_pair = len(pair_subject_ids)\n",
        "    k_all  = max(1, int(EPOCH_SUBJECT_FRACTION * n_all))\n",
        "    k_pair = max(1, int(EPOCH_SUBJECT_FRACTION * n_pair))\n",
        "\n",
        "    allowed_all  = rng.sample(all_subject_ids,  k_all)\n",
        "    allowed_pair = rng.sample(pair_subject_ids, k_pair)\n",
        "\n",
        "    ds = PairDataset(subjects_full, subjects_with_pairs_full, allowed_all, allowed_pair, p_pos=POS_PROB)\n",
        "    # steps ≈ (#timepoints in subset)/BATCH is hard to know exactly; approximate by scaling original steps\n",
        "    total_steps_full = math.ceil(len(pt_files) / BATCH_SIZE)\n",
        "    steps_this_epoch = max(60, int(total_steps_full * EPOCH_SUBJECT_FRACTION))  # ~472*0.25 ≈ 118\n",
        "    loader = DataLoader(\n",
        "        ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,\n",
        "        pin_memory=(device==\"cuda\"), drop_last=True\n",
        "    )\n",
        "    return loader, steps_this_epoch\n",
        "\n",
        "# ----------------------------------------\n",
        "# Model (lighter + faster)\n",
        "# ----------------------------------------\n",
        "class _ConvBlock(nn.Module):\n",
        "    def __init__(self, cin, cout):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv3d(cin, cout, 3, padding=1)\n",
        "        self.bn   = nn.BatchNorm3d(cout)\n",
        "        self.act  = nn.ReLU(inplace=True)\n",
        "    def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class SafeEncoder3D(nn.Module):\n",
        "    def __init__(self, in_ch=1, base=16, out_dim=256):  # base=16 (lighter than 32)\n",
        "        super().__init__()\n",
        "        self.b1=_ConvBlock(in_ch,base);       self.b2=_ConvBlock(base,base*2)\n",
        "        self.b3=_ConvBlock(base*2,base*4);    self.b4=_ConvBlock(base*4,base*8)\n",
        "        self.pool=nn.AdaptiveAvgPool3d(1);    self.fc=nn.Linear(base*8,out_dim)\n",
        "    def forward(self,x):\n",
        "        x=self.b1(F.max_pool3d(x,2))  # 96->48\n",
        "        x=self.b2(F.max_pool3d(x,2))  # 48->24\n",
        "        x=self.b3(F.max_pool3d(x,2))  # 24->12\n",
        "        x=self.b4(F.max_pool3d(x,2))  # 12->6\n",
        "        return self.fc(self.pool(x).flatten(1))\n",
        "\n",
        "class ContrastiveModel(nn.Module):\n",
        "    def __init__(self, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.backbone=SafeEncoder3D()\n",
        "        self.proj=nn.Sequential(nn.Linear(256,256), nn.ReLU(True), nn.Linear(256,proj_dim))\n",
        "    def forward(self,x):\n",
        "        h=self.backbone(x)\n",
        "        z=F.normalize(self.proj(h), dim=1)\n",
        "        return z,h\n",
        "\n",
        "model = ContrastiveModel(128).to(device)\n",
        "\n",
        "def info_nce(z1,z2,temp=0.07):\n",
        "    z1=F.normalize(z1,dim=1); z2=F.normalize(z2,dim=1)\n",
        "    logits=(z1@z2.t())/temp\n",
        "    labels=torch.arange(z1.size(0), device=z1.device)\n",
        "    return 0.5*(F.cross_entropy(logits,labels)+F.cross_entropy(logits.t(),labels))\n",
        "\n",
        "opt    = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "scaler = GradScaler(\"cuda\", enabled=(device==\"cuda\"))\n",
        "\n",
        "# Quick shape check on a small epoch subset\n",
        "_loader_preview, _ = make_loader_for_epoch(0)\n",
        "with torch.inference_mode():\n",
        "    a,b,y,p1,p2 = next(iter(_loader_preview))\n",
        "    print(f\"[check] batch a={tuple(a.shape)} b={tuple(b.shape)} y={y.tolist()[:8]}\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# Train with rotating subject subsets\n",
        "# ----------------------------------------\n",
        "total_steps_full = math.ceil(len(pt_files) / BATCH_SIZE)\n",
        "print(f\"\\n[train] epochs={EPOCHS} | full-steps≈{total_steps_full} | per-epoch fraction={EPOCH_SUBJECT_FRACTION}\")\n",
        "\n",
        "global_step=0; t_all=time.time()\n",
        "for ep in range(1, EPOCHS + 1):\n",
        "    loader, steps_per_epoch = make_loader_for_epoch(ep)\n",
        "    model.train(); running=[]; seen=set(); t0=time.time(); step=0\n",
        "\n",
        "    for x1, x2, _, p1s, p2s in loader:\n",
        "        for q in p1s: seen.add(q)\n",
        "        for q in p2s: seen.add(q)\n",
        "\n",
        "        x1 = x1.contiguous(memory_format=torch.channels_last_3d).to(device, non_blocking=True)\n",
        "        x2 = x2.contiguous(memory_format=torch.channels_last_3d).to(device, non_blocking=True)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with autocast(device_type=\"cuda\", enabled=(device == \"cuda\")):\n",
        "            z1, _ = model(x1)\n",
        "            z2, _ = model(x2)\n",
        "            loss = info_nce(z1, z2, temp=TEMP)\n",
        "        scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "\n",
        "        running.append(loss.item()); global_step += 1; step += 1\n",
        "        if PRINT_EVERY and (global_step % PRINT_EVERY == 0):\n",
        "            print(f\"  [ep {ep:02d} step {global_step:05d}] loss={np.mean(running):.4f}\")\n",
        "        if step >= steps_per_epoch: break\n",
        "\n",
        "    cov = 100.0 * len(seen) / len(pt_files) if pt_files else 0.0\n",
        "    print(f\"[ep {ep:02d}] time={time.time()-t0:.1f}s | steps={step} | mean_loss={np.mean(running):.4f} | coverage≈{cov:.2f}% (subset)\")\n",
        "\n",
        "    # ---- SAVE + UPLOAD EACH EPOCH ----\n",
        "    STAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    CKPT_PATH = f\"/content/clinimcl_contrastive_fast_ep{ep:02d}.pth\"\n",
        "    torch.save({\n",
        "        \"epoch\": ep,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": opt.state_dict(),\n",
        "        \"cfg\": {\n",
        "            \"IMG_SIZE\": IMG_SIZE,\n",
        "            \"TEMP\": TEMP,\n",
        "            \"proj_dim\": 128,\n",
        "            \"EPOCH_SUBJECT_FRACTION\": EPOCH_SUBJECT_FRACTION,\n",
        "            \"BATCH_SIZE\": BATCH_SIZE\n",
        "        }\n",
        "    }, CKPT_PATH)\n",
        "    print(f\"[save] wrote local {CKPT_PATH}\")\n",
        "\n",
        "    UPLOAD_PATH = f\"{CHECKPOINT_BUCKET}contrastive_fast_ep{ep:02d}_{STAMP}.pth\"\n",
        "    ret = os.system(f\"gsutil cp {CKPT_PATH} {UPLOAD_PATH}\")\n",
        "    if ret == 0:\n",
        "        print(f\"[upload] uploaded to {UPLOAD_PATH}\")\n",
        "        os.remove(CKPT_PATH)\n",
        "        print(\"[save] removed local checkpoint to free space\")\n",
        "    else:\n",
        "        print(\"[warn] upload failed; keeping local checkpoint\")\n",
        "\n",
        "\n",
        "print(f\"\\nTraining finished in {time.time()-t_all:.1f}s for {EPOCHS} epochs (rotating subject subsets)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYZaZlb_u99z",
        "outputId": "59108d2c-3d43-4ada-9a22-1ef764ecde95"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[env] device=cuda | epochs=10 | batch=8 | img=96\n",
            "[data] files=2832\n",
            "[data] subjects=1376 | with≥2 tps=685\n",
            "[check] batch a=(8, 1, 96, 96, 96) b=(8, 1, 96, 96, 96) y=[0, 1, 1, 1, 1, 1, 1, 0]\n",
            "\n",
            "[train] epochs=10 | full-steps≈354 | per-epoch fraction=0.25\n",
            "  [ep 01 step 00050] loss=2.0392\n",
            "[ep 01] time=2386.3s | steps=88 | mean_loss=2.0532 | coverage≈25.56% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep01.pth\n",
            "[warn] upload failed; keeping local checkpoint\n",
            "  [ep 02 step 00100] loss=2.0343\n",
            "  [ep 02 step 00150] loss=2.0659\n",
            "[ep 02] time=2452.5s | steps=88 | mean_loss=2.0569 | coverage≈25.56% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep02.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep02_20251110_010525.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 03 step 00200] loss=1.9822\n",
            "  [ep 03 step 00250] loss=1.9850\n",
            "[ep 03] time=2284.9s | steps=88 | mean_loss=1.9870 | coverage≈26.06% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep03.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep03_20251110_014335.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 04 step 00300] loss=1.9943\n",
            "  [ep 04 step 00350] loss=1.9903\n",
            "[ep 04] time=2405.1s | steps=88 | mean_loss=1.9919 | coverage≈25.78% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep04.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep04_20251110_022348.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 05 step 00400] loss=1.9705\n",
            "[ep 05] time=2555.3s | steps=88 | mean_loss=1.9848 | coverage≈25.53% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep05.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep05_20251110_030628.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 06 step 00450] loss=1.9352\n",
            "  [ep 06 step 00500] loss=1.9490\n",
            "[ep 06] time=2487.7s | steps=88 | mean_loss=1.9582 | coverage≈25.28% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep06.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep06_20251110_034803.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 07 step 00550] loss=1.9876\n",
            "  [ep 07 step 00600] loss=1.9566\n",
            "[ep 07] time=2567.0s | steps=88 | mean_loss=1.9379 | coverage≈25.25% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep07.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep07_20251110_043058.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 08 step 00650] loss=1.9637\n",
            "  [ep 08 step 00700] loss=1.9645\n",
            "[ep 08] time=2701.8s | steps=88 | mean_loss=1.9666 | coverage≈25.81% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep08.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep08_20251110_051607.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 09 step 00750] loss=1.9862\n",
            "[ep 09] time=2517.2s | steps=88 | mean_loss=1.9367 | coverage≈25.60% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep09.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep09_20251110_055809.pth\n",
            "[save] removed local checkpoint to free space\n",
            "  [ep 10 step 00800] loss=1.9390\n",
            "  [ep 10 step 00850] loss=1.9610\n",
            "[ep 10] time=2427.1s | steps=88 | mean_loss=1.9408 | coverage≈24.01% (subset)\n",
            "[save] wrote local /content/clinimcl_contrastive_fast_ep10.pth\n",
            "[upload] uploaded to gs://clinimcl-data/checkpoints/contrastive_fast_ep10_20251110_063844.pth\n",
            "[save] removed local checkpoint to free space\n",
            "\n",
            "Training finished in 24846.1s for 10 epochs (rotating subject subsets)\n"
          ]
        }
      ]
    }
  ]
}